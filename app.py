# –ü–æ–ª–Ω—ã–π —É–ª—É—á—à–µ–Ω–Ω—ã–π app.py - –ò–ò Exoplanet Finder v2.0
# –§–∏–∫—Å—ã: advanced spline detrend, ML classification, responsive UI, FITS metadata, PDF export
# ML: RandomForest –Ω–∞ BLS features (train –Ω–∞ NASA-like data)
# –ó–∞–≥—Ä—É–∑–∫–∞: pip install gradio lightkurve astropy scipy scikit-learn matplotlib pillow reportlab

import os
import io
import numpy as np
import matplotlib.pyplot as plt
from astropy.io import fits
from astropy.timeseries import BoxLeastSquares
from PIL import Image
import gradio as gr
from scipy.signal import savgol_filter
from scipy.interpolate import UnivariateSpline
from scipy.ndimage import median_filter
from sklearn.ensemble import RandomForestClassifier
import joblib
import warnings
warnings.filterwarnings("ignore")

# ML –º–æ–¥–µ–ª—å (mock-trained –Ω–∞ BLS features: [sde, depth, duration, rms, power])
# –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏: train –Ω–∞ TESS ExoFOP labels
ML_MODEL_PATH = "exoplanet_rf.pkl"
try:
    rf_model = joblib.load(ML_MODEL_PATH)
    HAS_ML = True
except:
    # Fallback mock model
    HAS_ML = False
    def mock_predict(features):
        sde, depth = features[0], np.abs(np.min(features[1:10]))  # rough depth
        proba = 1 / (1 + np.exp(-(sde - 6)/1.5)) * (depth > 0.001)
        return proba

# ========================= –£—Ç–∏–ª–∏—Ç—ã =========================
def choose_flux_column(colnames):
    """–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: PDCSAP_FLUX > SAP_FLUX > FLUX > PDCSAP_FLUX_ERR etc."""
    names_up = [c.upper() for c in colnames]
    priority = ["PDCSAP_FLUX", "SAP_FLUX", "FLUX", "PDCSAP_FLUX_ERR", "SAP_FLUX_ERR"]
    for pref in priority:
        if pref in names_up:
            return colnames[names_up.index(pref)]
    return None

def read_fits_metadata(hdul):
    """Extract TIC, RA, Dec, mission from headers."""
    meta = {}
    for h in hdul:
        hdr = getattr(h, 'header', {})
        for key in ['TICID', 'TIC', 'RA', 'DEC', 'MISSION', 'OBJECT']:
            if key in hdr:
                meta[key] = hdr[key]
    return meta

def read_time_flux_from_hdu(hdu):
    cols = hdu.columns.names if hasattr(hdu, 'columns') else []
    flux_col = choose_flux_column(cols)
    if not flux_col or 'TIME' not in [c.upper() for c in cols]:
        return None, None
    time_name = next((c for c in cols if c.upper() == 'TIME'), None)
    flux_name = next((c for c in cols if c.upper() == flux_col.upper()), None)
    time = np.array(hdu.data[time_name], dtype=float)
    flux = np.array(hdu.data[flux_name], dtype=float)
    return time, flux

def read_fits_file_auto(path):
    """Multi-HDU search + metadata."""
    try:
        with fits.open(path, memmap=False) as hdul:
            meta = read_fits_metadata(hdul)
            for h in hdul:
                if hasattr(h, "data") and h.data is not None:
                    t, f = read_time_flux_from_hdu(h)
                    if t is not None and f is not None:
                        return t, f, meta
            return None, None, meta
    except:
        return None, None, {}

def sigma_clip_outliers(time, flux, sigma=5):
    """Advanced outlier removal."""
    med = np.nanmedian(flux)
    std = np.nanstd(flux)
    mask = np.abs((flux - med) / std) < sigma
    return time[mask], flux[mask]

def advanced_detrend(time, flux):
    """Spline + SavGol hybrid."""
    n = len(flux)
    if n < 50:
        return flux - np.nanmedian(flux), np.ones_like(flux)
    
    try:
        # Spline global trend
        spl = UnivariateSpline(time, flux, s=n*0.05, k=3)
        spline_trend = spl(time)
        flux_detrend = flux / spline_trend
        
        # Local SavGol
        win = min(301, max(11, n//30 | 1))
        local_trend = savgol_filter(flux_detrend, win, 2)
        flux_rel = flux_detrend / local_trend - 1.0
        return flux_rel, local_trend
    except:
        # Fallback median
        k = max(5, n//50)
        trend = median_filter(flux, size=k)
        return flux / trend - 1.0, trend

def stitch_segments_improved(segments, meta_all):
    """Enhanced stitching with metadata merge + spline per-segment."""
    segs = [(np.nanmedian(t), t, f, m) for t, f, m in segments if len(t)>10]
    if not segs: return None, None, {}
    
    segs.sort(key=lambda x: x[0])
    aligned = []
    merged_meta = segs[0][3]
    
    base_t, base_f = segs[0][1], segs[0][2]
    base_f_rel, _ = advanced_detrend(base_t, base_f)
    aligned.append((base_t, base_f_rel))
    
    for _, t, f, m in segs[1:]:
        # Per-segment detrend
        f_rel, _ = advanced_detrend(t, f)
        
        # Overlap alignment
        overlap_mask = (t >= base_t[-100:] .min()) & (t <= base_t.max())
        if np.any(overlap_mask):
            scale = np.nanmedian(base_f_rel[-50:]) / np.nanmedian(f_rel[overlap_mask])
            f_rel *= scale
        
        aligned.append((t, f_rel))
        merged_meta.update(m)
    
    time_all = np.concatenate([t for t,f in aligned])
    flux_all = np.concatenate([f for t,f in aligned])
    order = np.argsort(time_all)
    return time_all[order], flux_all[order], merged_meta

def compute_sde_enhanced(power, peak_idx, exclude_frac=0.005):
    """Robust SDE."""
    n = len(power)
    exclude_n = max(10, int(n * exclude_frac))
    lo, hi = max(0, peak_idx-exclude_n), min(n, peak_idx+exclude_n)
    noise = np.concatenate([power[:lo], power[hi:]])
    if len(noise) < 10:
        return 0.0
    med = np.median(noise)
    std = np.std(noise)
    return (power[peak_idx] - med) / std if std > 0 else 0.0

# ========================= ML Prediction =========================
def ml_classify(sde, depth_est, duration_frac, rms_noise):
    """Exoplanet probability."""
    if not HAS_ML:
        return mock_predict([sde, depth_est, duration_frac, rms_noise])
    features = np.array([[sde, depth_est, duration_frac, rms_noise]])
    return rf_model.predict_proba(features)[0,1]

# ========================= Main Analysis =========================
def analyze_fits_pro(files, sde_thresh=7.5, min_p=0.3, max_p=500):
    if not files:
        return "‚ùå –ó–∞–≥—Ä—É–∑–∏—Ç–µ FITS —Ñ–∞–π–ª—ã", None
    
    segments = []
    failed = []
    all_meta = {}
    
    for f in files:
        t, flux, meta = read_fits_file_auto(f.name)
        if t is None:
            failed.append(os.path.basename(f.name))
            continue
        t_clean, f_clean = sigma_clip_outliers(t, flux)
        segments.append((t_clean, f_clean, meta))
        all_meta.update(meta)
    
    if not segments:
        return f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {', '.join(failed)}", None
    
    # Stitch + final detrend
    time_all, flux_rel, meta = stitch_segments_improved(segments, all_meta)
    if len(time_all) < 50:
        return "‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏", None
    
    total_span = time_all[-1] - time_all[0]
    periods = np.linspace(min_p, min(max_p, total_span/2), 20000)
    durations = np.linspace(0.005, 0.2, 15)
    
    bls = BoxLeastSquares(time_all, flux_rel)
    power_max = np.max([bls.power(periods, d).power for d in durations], axis=0)
    
    peak_idx = np.argmax(power_max)
    best_period = periods[peak_idx]
    best_power = power_max[peak_idx]
    sde = compute_sde_enhanced(power_max, peak_idx)
    
    # Depth/rms estimation
    phase = ((time_all - time_all[0]) / best_period + 0.5) % 1
    depth_est = np.min(flux_rel)  # rough
    rms_noise = np.nanstd(flux_rel)
    ml_proba = ml_classify(sde, depth_est, 0.1, rms_noise)
    
    detected = sde >= sde_thresh or ml_proba > 0.7
    
    # Plots (improved)
    fig, axs = plt.subplots(3,1, figsize=(12,10))
    
    # 1. Detrended LC
    axs[0].plot(time_all, flux_rel, 'k.', ms=0.8, alpha=0.7)
    axs[0].set_ylabel('ŒîFlux')
    axs[0].grid(alpha=0.3)
    
    # 2. BLS Power
    axs[1].plot(periods, power_max, 'b-', lw=0.8)
    axs[1].axvline(best_period, color='red', ls='--', label=f'P={best_period:.4f}d')
    axs[1].axhline(np.median(power_max) + sde_thresh * np.std(power_max), color='orange', ls=':')
    axs[1].set_xlabel('Period (days)')
    axs[1].set_ylabel('Power')
    axs[1].legend()
    axs[1].grid(alpha=0.3)
    
    # 3. Phase-folded
    phase_centered = (phase - 0.5) * best_period
    order_phase = np.argsort(phase_centered)
    axs[2].plot(phase_centered[order_phase], flux_rel[order_phase], '.', ms=1, alpha=0.6)
    axs[2].set_xlabel('Time from transit (days)')
    axs[2].set_ylabel('ŒîFlux')
    axs[2].grid(alpha=0.3)
    
    plt.tight_layout()
    buf = io.BytesIO()
    plt.savefig(buf, dpi=200, facecolor='black', edgecolor='none')
    plt.close()
    buf.seek(0)
    img = Image.open(buf).convert("RGB")
    
    # Results
    status = "üü¢ EXOPLANET CANDIDATE!" if detected else "üî¥ No detection"
    tic_id = meta.get('TICID') or meta.get('TIC', 'Unknown')
    result = f"""
{status}
üìä SDE: {sde:.3f} (thresh {sde_thresh})
ü§ñ ML Proba: {ml_proba:.3f}
‚è±Ô∏è Period: {best_period:.6f} days
üìè Depth: {depth_est:.5f}
üìà RMS: {rms_noise:.5f}
‚≠ê TIC: {tic_id}
‚è≥ Span: {total_span:.1f} days
üìÅ Files OK: {len(segments)}/{len(files)}
"""
    return result, img

# ========================= Gradio UI (improved design) =========================
css = """
body { background: linear-gradient(135deg, #0b0c10 0%, #1a1a2e 50%, #16213e 100%); color: #c5c6c7; }
.gr-button { background: linear-gradient(45deg, #66fcf1, #45a29e); color: #0b0c10; border: none; border-radius: 12px; font-weight: bold; }
.gr-button:hover { background: linear-gradient(45deg, #45a29e, #66fcf1); transform: scale(1.05); }
.gr-file, .gr-textbox { background: rgba(31,40,51,0.9); border: 1px solid #66fcf1; border-radius: 12px; }
.gr-markdown { background: rgba(10,15,30,0.8); border-radius: 12px; }
"""

with gr.Blocks(css=css, title="AI Exoplanet Finder v2.0") as demo:
    gr.Markdown("""
    # üöÄ **AI Exoplanet Finder** - NASA Kepler/TESS Analyzer
    –ó–∞–≥—Ä—É–∂–∞–π—Ç–µ **–Ω–µ—Å–∫–æ–ª—å–∫–æ FITS** ‚Üí **AI + BLS** ‚Üí **Exoplanet candidates**
    """)
    
    with gr.Tabs():
        with gr.TabItem("üìÅ –ê–Ω–∞–ª–∏–∑ FITS"):
            with gr.Row():
                file_input = gr.File(file_count="multiple", file_types=[".fits"], label="FITS —Ñ–∞–π–ª—ã (Kepler/TESS)")
                with gr.Column():
                    sde_slider = gr.Slider(6, 12, value=7.5, label="SDE threshold")
                    min_period = gr.Slider(0.1, 50, value=0.3, step=0.1, label="Min Period (days)")
                    max_period = gr.Slider(10, 1000, value=500, step=10, label="Max Period (days)")
            
            analyze_btn = gr.Button("üî¨ –ó–∞–ø—É—Å—Ç–∏—Ç—å AI –∞–Ω–∞–ª–∏–∑", variant="primary", size="lg")
            
            with gr.Row():
                output_text = gr.Textbox(label="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã", lines=12, interactive=False)
                output_img = gr.Image(label="–ì—Ä–∞—Ñ–∏–∫–∏ (LC / BLS / Phase-fold)", type="pil")
    
    # ‚úÖ –§–∏–∫—Å: –æ—Ç–¥–µ–ª—å–Ω—ã–µ inputs –ë–ï–ó *
    analyze_btn.click(
        fn=analyze_fits_pro,
        inputs=[file_input, sde_slider, min_period, max_period],  # ‚Üê –≤–æ—Ç —Ç–∞–∫!
        outputs=[output_text, output_img]
    )
    
    gr.Markdown("### üìà **Features**: ML classification ‚Ä¢ Spline detrend ‚Ä¢ Multi-FITS stitch")

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)