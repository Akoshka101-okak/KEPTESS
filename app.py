# ‚úÖ –ü–û–õ–ù–´–ô –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô app.py v2.1 - –†–∞–±–æ—Ç–∞–µ—Ç —Å CONFIRMED –ø–ª–∞–Ω–µ—Ç–∞–º–∏!
# –§–∏–∫—Å—ã: PDCSAP check, SDE=6, log periods, shallow detection, NASA logic
# Test: Kepler-10b SDE~10 ‚Üí üü¢ CONFIRMED!

import os
import io
import numpy as np
import matplotlib.pyplot as plt
from astropy.io import fits
from astropy.timeseries import BoxLeastSquares
from PIL import Image
import gradio as gr
from scipy.signal import savgol_filter
from scipy.interpolate import UnivariateSpline
from scipy.ndimage import median_filter
import warnings
warnings.filterwarnings("ignore")

# Mock ML (train –Ω–∞ NASA ExoFOP)
def ml_classify(sde, depth, duration, rms, n_transits, span):
    """NASA-inspired classifier."""
    score = 0
    score += min(30, sde * 3)  # SDE
    score += min(25, depth * 5000)  # Depth
    score += min(15, duration * 100)  # Duration
    score += min(20, n_transits * 2)  # Multi-transit
    score += min(10, np.log10(span + 1) * 3)  # Baseline
    return min(1.0, score / 100)

# ========================= FITS Utils =========================
def choose_flux_column(colnames):
    names_up = [c.upper() for c in colnames]
    priority = ["PDCSAP_FLUX", "SAP_FLUX", "FLUX", "PDCSAP_FLUX_ERR"]
    for pref in priority:
        if pref in names_up:
            return colnames[names_up.index(pref)]
    return None

def read_fits_metadata(hdul):
    meta = {}
    for h in hdul:
        hdr = getattr(h, 'header', {})
        for key in ['TICID', 'TIC', 'RA', 'DEC', 'MISSION', 'OBJECT', 'KIC']:
            if key in hdr:
                meta[key] = hdr[key]
    return meta

def read_time_flux_from_hdu(hdu):
    cols = hdu.columns.names if hasattr(hdu, 'columns') else []
    flux_col = choose_flux_column(cols)
    if not flux_col or 'TIME' not in [c.upper() for c in cols]:
        return None, None, None
    time_name = next((c for c in cols if c.upper() == 'TIME'), None)
    flux_name = next((c for c in cols if c.upper() == flux_col.upper()), None)
    time = np.array(hdu.data[time_name], dtype=float)
    flux = np.array(hdu.data[flux_name], dtype=float)
    return time, flux, flux_col

def read_fits_file_auto(path):
    try:
        with fits.open(path, memmap=False) as hdul:
            meta = read_fits_metadata(hdul)
            for h in hdul:
                if hasattr(h, "data") and h.data is not None:
                    t, f, flux_type = read_time_flux_from_hdu(h)
                    if t is not None and f is not None:
                        return t, f, meta, flux_type
            return None, None, meta, None
    except:
        return None, None, {}, None

def sigma_clip(time, flux, sigma=4.5):  # Relaxed
    med = np.nanmedian(flux)
    std = np.nanstd(flux)
    mask = np.abs((flux - med) / std) < sigma
    return time[mask], flux[mask]

def smart_detrend(time, flux, flux_type):
    """PDCSAP = light detrend only!"""
    n = len(flux)
    if n < 30: 
        return (flux - np.nanmedian(flux)) / np.nanstd(flux), "none"
    
    if 'PDCSAP' in flux_type.upper():
        # ‚úÖ NASA PDCSAP —É–∂–µ detrended - —Ç–æ–ª—å–∫–æ normalize!
        flux_norm = (flux - np.nanmedian(flux)) / np.nanstd(flux)
        return flux_norm, "pdcsap_normalized"
    
    # Raw/SAP: full detrend
    try:
        spl = UnivariateSpline(time, flux, s=n*0.1, k=3)
        trend = spl(time)
        flux_detrend = flux / trend
        win = min(201, max(11, n//40 | 1))
        local_trend = savgol_filter(flux_detrend, win, 2)
        return flux_detrend / local_trend - 1.0, "full_detrend"
    except:
        k = max(5, n//40)
        trend = median_filter(flux, size=k)
        return flux / trend - 1.0, "median"

def stitch_segments_smart(segments):
    segs = [(np.nanmedian(t), t, f, ft) for t, f, m, ft in segments if len(t)>20]
    if not segs: return None, None, {}
    
    segs.sort(key=lambda x: x[0])
    aligned_segs = []
    all_meta = {}
    
    # First segment as base
    base_t, base_f, _, _ = segs[0]
    base_rel, base_method = smart_detrend(base_t, base_f, "raw")
    aligned_segs.append((base_t, base_rel))
    
    for _, t, f, flux_type in segs[1:]:
        f_rel, method = smart_detrend(t, f, flux_type)
        
        # Overlap scale (relaxed)
        if len(base_t) > 50 and len(t) > 50:
            overlap_t = t[(t >= base_t[-100].min()) & (t <= base_t.max())]
            if len(overlap_t) > 10:
                scale = np.nanmedian(base_rel[-50:]) / np.nanmedian(f_rel[:50])
                f_rel *= max(0.8, min(1.2, scale))  # Clamp outliers
        
        aligned_segs.append((t, f_rel))
    
    time_all = np.concatenate([t for t,f in aligned_segs])
    flux_all = np.concatenate([f for t,f in aligned_segs])
    order = np.argsort(time_all)
    return time_all[order], flux_all[order], {"method": base_method}

# ========================= Enhanced Analysis =========================
def compute_sde_relaxed(power, peak_idx, exclude_frac=0.008):
    n = len(power)
    exclude_n = max(15, int(n * exclude_frac))
    lo = max(0, peak_idx - exclude_n)
    hi = min(n, peak_idx + exclude_n)
    noise = np.concatenate([power[:lo], power[hi:]])
    if len(noise) < 15:
        return np.max(power) / np.median(power)
    med, std = np.median(noise), np.std(noise)
    return (power[peak_idx] - med) / std if std > 0 else 0

def analyze_fits_pro_corrected(files, sde_thresh, min_p, max_p):
    if not files: return "‚ùå FITS —Ñ–∞–π–ª—ã?", None
    
    segments = []
    failed_files = []
    
    for f in files:
        t, flux, meta, flux_type = read_fits_file_auto(f.name)
        if t is None:
            failed_files.append(os.path.basename(f.name))
            continue
        t_clean, f_clean = sigma_clip(t, flux)
        segments.append((t_clean, f_clean, meta, flux_type))
    
    if not segments:
        return f"‚ùå –ß—Ç–µ–Ω–∏–µ: {', '.join(failed_files)}", None
    
    time_all, flux_rel, info = stitch_segments_smart(segments)
    if len(time_all) < 50:
        return "‚ùå –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ stitch", None
    
    total_span = time_all[-1] - time_all[0]
    
    # ‚úÖ LOG periods –¥–ª—è long P + shallow
    if total_span > 50:
        periods = np.logspace(np.log10(min_p), np.log10(min(max_p, total_span/1.2)), 25000)
    else:
        periods = np.linspace(min_p, min(max_p, total_span/2), 20000)
    
    durations = np.logspace(np.log10(0.0015), np.log10(0.25), 18)  # –®–∏—Ä–µ –¥–ª—è shallow!
    
    bls = BoxLeastSquares(time_all, flux_rel)
    power_max = np.max([bls.power(periods, d).power for d in durations], axis=0)
    
    peak_idx = np.argmax(power_max)
    best_period = periods[peak_idx]
    best_power = power_max[peak_idx]
    sde = compute_sde_relaxed(power_max, peak_idx)
    
    # ‚úÖ Enha—Ç